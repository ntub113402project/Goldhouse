{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0fab400-77f8-4beb-9ae4-abbf1a216765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始進行文字相似度比對...\n",
      "文字相似度比對結果:\n",
      "文字相似 HID1: 16325563, HID2: 16356457\n",
      "\n",
      "開始進行圖片相似度比對...\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image1.jpg: 480x640 1 person, 1 bed, 298.9ms\n",
      "Speed: 9.0ms preprocess, 298.9ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 240.5ms\n",
      "Speed: 6.0ms preprocess, 240.5ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 171.8ms\n",
      "Speed: 7.0ms preprocess, 171.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 200.9ms\n",
      "Speed: 5.1ms preprocess, 200.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 223.2ms\n",
      "Speed: 7.0ms preprocess, 223.2ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 216.2ms\n",
      "Speed: 5.0ms preprocess, 216.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 194.0ms\n",
      "Speed: 5.0ms preprocess, 194.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image2.jpg: 480x640 1 bed, 251.1ms\n",
      "Speed: 5.0ms preprocess, 251.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 295.6ms\n",
      "Speed: 5.0ms preprocess, 295.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 266.5ms\n",
      "Speed: 8.0ms preprocess, 266.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 274.1ms\n",
      "Speed: 6.2ms preprocess, 274.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 185.5ms\n",
      "Speed: 6.0ms preprocess, 185.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 201.4ms\n",
      "Speed: 5.0ms preprocess, 201.4ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 192.3ms\n",
      "Speed: 5.0ms preprocess, 192.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 202.7ms\n",
      "Speed: 5.0ms preprocess, 202.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image3.jpg: 480x640 1 bed, 291.5ms\n",
      "Speed: 5.0ms preprocess, 291.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 293.6ms\n",
      "Speed: 5.0ms preprocess, 293.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 252.0ms\n",
      "Speed: 5.0ms preprocess, 252.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 288.2ms\n",
      "Speed: 5.0ms preprocess, 288.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 234.9ms\n",
      "Speed: 5.4ms preprocess, 234.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 233.4ms\n",
      "Speed: 5.0ms preprocess, 233.4ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 253.9ms\n",
      "Speed: 6.1ms preprocess, 253.9ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 205.6ms\n",
      "Speed: 9.5ms preprocess, 205.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image4.jpg: 480x640 1 bed, 192.0ms\n",
      "Speed: 19.8ms preprocess, 192.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 287.5ms\n",
      "Speed: 5.0ms preprocess, 287.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 221.3ms\n",
      "Speed: 8.8ms preprocess, 221.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 229.8ms\n",
      "Speed: 7.0ms preprocess, 229.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 276.0ms\n",
      "Speed: 5.1ms preprocess, 276.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 242.0ms\n",
      "Speed: 5.0ms preprocess, 242.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 210.9ms\n",
      "Speed: 5.7ms preprocess, 210.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 245.0ms\n",
      "Speed: 5.0ms preprocess, 245.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image5.jpg: 480x640 2 bottles, 2 toilets, 1 sink, 195.3ms\n",
      "Speed: 10.7ms preprocess, 195.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 241.1ms\n",
      "Speed: 6.0ms preprocess, 241.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 333.3ms\n",
      "Speed: 5.0ms preprocess, 333.3ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 267.6ms\n",
      "Speed: 8.1ms preprocess, 267.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 381.9ms\n",
      "Speed: 5.0ms preprocess, 381.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 229.5ms\n",
      "Speed: 4.2ms preprocess, 229.5ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 243.8ms\n",
      "Speed: 6.6ms preprocess, 243.8ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 236.0ms\n",
      "Speed: 4.5ms preprocess, 236.0ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image6.jpg: 480x640 (no detections), 264.5ms\n",
      "Speed: 7.3ms preprocess, 264.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 273.0ms\n",
      "Speed: 5.0ms preprocess, 273.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 252.6ms\n",
      "Speed: 6.0ms preprocess, 252.6ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 246.8ms\n",
      "Speed: 7.0ms preprocess, 246.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 297.0ms\n",
      "Speed: 4.0ms preprocess, 297.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 334.1ms\n",
      "Speed: 7.0ms preprocess, 334.1ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 238.2ms\n",
      "Speed: 5.0ms preprocess, 238.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 218.6ms\n",
      "Speed: 4.3ms preprocess, 218.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16325563\\image7.jpg: 480x640 1 person, 246.6ms\n",
      "Speed: 13.0ms preprocess, 246.6ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image1.jpg: 512x640 1 bed, 251.0ms\n",
      "Speed: 6.0ms preprocess, 251.0ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image2.jpg: 512x640 1 bed, 288.8ms\n",
      "Speed: 8.0ms preprocess, 288.8ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image3.jpg: 512x640 1 bed, 203.2ms\n",
      "Speed: 5.0ms preprocess, 203.2ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image4.jpg: 512x640 (no detections), 230.4ms\n",
      "Speed: 5.0ms preprocess, 230.4ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image5.jpg: 512x640 1 person, 258.1ms\n",
      "Speed: 7.0ms preprocess, 258.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image6.jpg: 512x640 (no detections), 312.8ms\n",
      "Speed: 6.0ms preprocess, 312.8ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 C:\\Users\\user\\OneDrive\\\\gold_house-\\16356457\\image7.jpg: 512x640 (no detections), 296.7ms\n",
      "Speed: 9.0ms preprocess, 296.7ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "圖片相似度比對結果:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ckiptagger import WS\n",
    "from transformers import BertTokenizer, BertModel, CLIPProcessor, CLIPModel\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialize models\n",
    "ws = WS(\"C:\\\\Users\\\\user\\\\OneDrive\\\\桌面\\\\data\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "bert_model = BertModel.from_pretrained('bert-base-chinese')\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def preprocess_data(items):\n",
    "    for item in items:\n",
    "        address_text = ' '.join([str(a).strip() for a in item['positionround'].get('address', [])])\n",
    "        address_tokens = ws([address_text])\n",
    "        item['address_emb'] = get_bert_embedding(' '.join(address_tokens[0]))\n",
    "    return items\n",
    "\n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    return F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n",
    "\n",
    "def device_similarity(devices1, devices2):\n",
    "    common_devices = set(d1['device'] for d1 in devices1).intersection(set(d2['device'] for d2 in devices2))\n",
    "    matched = sum(1 for d1 in devices1 for d2 in devices2 if d1['device'] == d2['device'] and d1['avaliable'] == d2['avaliable'])\n",
    "    return matched / min(len(devices1), len(devices2)) >= 0.7\n",
    "\n",
    "def compare_patterns(pattern1, pattern2):\n",
    "    return (len(set(pattern1.split()).intersection(pattern2.split())) / min(len(pattern1.split()), len(pattern2.split()))) > 0.9\n",
    "\n",
    "def compare_layers(layer1, layer2):\n",
    "    layers1 = set(layer1.split('/'))\n",
    "    layers2 = set(layer2.split('/'))\n",
    "    return bool(layers1.intersection(layers2))\n",
    "\n",
    "def find_text_similar_items(data):\n",
    "    similar_items = set()  # 使用 set 來儲存避免重複的 pair\n",
    "    n = len(data)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # 進行地址相似度比較\n",
    "            address_similarity = cosine_similarity(data[i]['address_emb'], data[j]['address_emb']) > 0.9\n",
    "            if address_similarity:\n",
    "                # 如果地址相似，則進行其他屬性比對\n",
    "                pattern_match = compare_patterns(data[i]['houseinfo']['pattern'], data[j]['houseinfo']['pattern'])\n",
    "                size_match = compare_patterns(data[i]['houseinfo']['size'], data[j]['houseinfo']['size'])\n",
    "                layer_match = compare_layers(data[i]['houseinfo']['layer'], data[j]['houseinfo']['layer'])\n",
    "                device_match = device_similarity(data[i]['servicelist'], data[j]['servicelist'])\n",
    "                \n",
    "                # 當所有條件都符合時，記錄這對房屋，並保證順序一致 (min, max)\n",
    "                if pattern_match and size_match and layer_match and device_match:\n",
    "                    similar_items.add((min(data[i]['hid'], data[j]['hid']), max(data[i]['hid'], data[j]['hid'])))\n",
    "    return list(similar_items)\n",
    "\n",
    "def detect_objects(image_path):\n",
    "    results = yolo_model(image_path)\n",
    "    image = Image.open(image_path)\n",
    "    objects = results[0].boxes.xyxy.cpu().numpy()\n",
    "    return objects, image\n",
    "\n",
    "def get_dominant_color(image):\n",
    "    image = image.resize((50, 50))  \n",
    "    pixels = np.array(image).reshape(-1, 3)\n",
    "    counter = Counter(map(tuple, pixels))\n",
    "    dominant_color = counter.most_common(1)[0][0]\n",
    "    return dominant_color\n",
    "\n",
    "def generate_clip_description(image, objects):\n",
    "    descriptions = []\n",
    "    for obj in objects:\n",
    "        x1, y1, x2, y2 = map(int, obj[:4])\n",
    "        cropped_image = image.crop((x1, y1, x2, y2))\n",
    "        dominant_color = get_dominant_color(cropped_image)\n",
    "        color_name = f\"{dominant_color}\"\n",
    "        inputs = clip_processor(images=cropped_image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.get_image_features(**inputs)\n",
    "        texts = [f\"a {color_name} object\"] * 20\n",
    "        text_inputs = clip_processor(text=texts, return_tensors=\"pt\", padding=True)\n",
    "        text_features = clip_model.get_text_features(**text_inputs)\n",
    "        similarities = F.cosine_similarity(image_features, text_features)\n",
    "        best_match = similarities.argmax().item()\n",
    "        descriptions.append((texts[best_match], dominant_color))\n",
    "    return descriptions\n",
    "\n",
    "def calculate_image_similarity(desc1, desc2):\n",
    "    similarity_scores = []\n",
    "    for d1, d2 in zip(desc1, desc2):\n",
    "        text1, _ = d1\n",
    "        text2, _ = d2\n",
    "        text_emb1 = clip_processor(text=[text1], return_tensors=\"pt\", padding=True)\n",
    "        text_emb2 = clip_processor(text=[text2], return_tensors=\"pt\", padding=True)\n",
    "        text_features1 = clip_model.get_text_features(**text_emb1)\n",
    "        text_features2 = clip_model.get_text_features(**text_emb2)\n",
    "        cosine_sim = F.cosine_similarity(text_features1, text_features2).item()\n",
    "        similarity_scores.append(cosine_sim)\n",
    "    \n",
    "    return sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0\n",
    "\n",
    "def process_image_similarity(img1, img2, threshold=0.5):  # 設定較低的閥值\n",
    "    image_path1, desc1 = img1\n",
    "    image_path2, desc2 = img2\n",
    "    return calculate_image_similarity(desc1, desc2) > threshold  # 閥值由 0.8 調整為 0.6\n",
    "\n",
    "def find_image_similar_items(text_similar_items, image_folder, threshold=0.6):\n",
    "    similar_items = []\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for hid1, hid2 in text_similar_items:\n",
    "            images1 = os.listdir(os.path.join(image_folder, str(hid1)))\n",
    "            images2 = os.listdir(os.path.join(image_folder, str(hid2)))\n",
    "            \n",
    "            # 使用多線程並行處理圖片相似度\n",
    "            image_pairs = []\n",
    "            for img1 in images1:\n",
    "                image_path1 = os.path.join(image_folder, str(hid1), img1)\n",
    "                objects1, image1 = detect_objects(image_path1)\n",
    "                desc1 = generate_clip_description(image1, objects1)\n",
    "                for img2 in images2:\n",
    "                    image_path2 = os.path.join(image_folder, str(hid2), img2)\n",
    "                    objects2, image2 = detect_objects(image_path2)\n",
    "                    desc2 = generate_clip_description(image2, objects2)\n",
    "                    image_pairs.append(((image_path1, desc1), (image_path2, desc2)))\n",
    "            \n",
    "            # 並行計算圖片相似度\n",
    "            results = list(executor.map(lambda pair: process_image_similarity(pair[0], pair[1], threshold), image_pairs))\n",
    "            if all(results):\n",
    "                similar_items.append((hid1, hid2))\n",
    "    \n",
    "    return similar_items\n",
    "\n",
    "def main():\n",
    "    # 讀取資料並預處理\n",
    "    json_data = load_json(\"C:\\\\Users\\\\user\\\\OneDrive\\\\桌面\\\\detail-複製.json\")\n",
    "    complete_data = preprocess_data(json_data)\n",
    "    \n",
    "    # 文字相似度比對\n",
    "    print(\"開始進行文字相似度比對...\")\n",
    "    text_similar_items = find_text_similar_items(complete_data)\n",
    "    \n",
    "    # 輸出文字相似度比對結果\n",
    "    print(\"文字相似度比對結果:\")\n",
    "    for hid1, hid2 in text_similar_items:\n",
    "        print(f\"文字相似 HID1: {hid1}, HID2: {hid2}\")\n",
    "    \n",
    "    # 開始進行圖片相似度比對\n",
    "    image_folder = \"C:\\\\Users\\\\user\\\\OneDrive\\\\桌面\\\\gold_house-複製\"\n",
    "    print(\"\\n開始進行圖片相似度比對...\")\n",
    "    image_similar_items = find_image_similar_items(text_similar_items, image_folder, threshold=0.6)  # 設定較低的閥值\n",
    "    \n",
    "    # 輸出圖片相似度比對結果\n",
    "    print(\"圖片相似度比對結果:\")\n",
    "    for hid1, hid2 in image_similar_items:\n",
    "        print(f\"圖片相似 HID1: {hid1}, HID2: {hid2}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86a351-a891-42f6-8f16-f4ce6e7ebeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
