{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166a632d-fd52-4a6f-bc8c-df4d2a76723e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mckiptagger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WS\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from ckiptagger import WS\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化 Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 初始化 CKIP、BERT、YOLO\n",
    "ws = WS(\"C:\\\\Users\\\\user\\\\OneDrive\\\\桌面\\\\data\")\n",
    "tokenizer_zh = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "bert_model_zh = BertModel.from_pretrained('bert-base-chinese')\n",
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# BERT 嵌入計算\n",
    "def get_bert_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().tolist()\n",
    "\n",
    "# YOLO 偵測物件\n",
    "@app.route('/detect_objects', methods=['POST'])\n",
    "def detect_objects():\n",
    "    data = request.json\n",
    "    image_path = data.get('image_path')\n",
    "    if not image_path:\n",
    "        return jsonify({'error': '缺少圖片路徑'}), 400\n",
    "\n",
    "    results = yolo_model(image_path)\n",
    "    labels = [yolo_model.names[int(cls)] for cls in results[0].boxes.cls.tolist()]\n",
    "\n",
    "    return jsonify({'labels': labels}), 200\n",
    "\n",
    "# 文字 WS 與 BERT 嵌入\n",
    "@app.route('/process_text', methods=['POST'])\n",
    "def process_text():\n",
    "    data = request.json\n",
    "    text = data.get('text')\n",
    "    if not text:\n",
    "        return jsonify({'error': '缺少文本內容'}), 400\n",
    "\n",
    "    tokens = ws([text])\n",
    "    bert_embedding = get_bert_embedding(' '.join(tokens[0]), tokenizer_zh, bert_model_zh)\n",
    "\n",
    "    return jsonify({'tokens': tokens[0], 'embedding': bert_embedding}), 200\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
